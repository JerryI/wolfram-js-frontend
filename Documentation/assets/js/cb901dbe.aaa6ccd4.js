"use strict";(self.webpackChunkwlx_docs=self.webpackChunkwlx_docs||[]).push([[684],{49180:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>d,frontMatter:()=>i,metadata:()=>t,toc:()=>l});var o=a(17624),r=a(4552);const i={authors:"jerryi",enableComments:!0,slug:"image-trace",tags:["animation"]},s="Image tracing and animation",t={permalink:"/blog/image-trace",source:"@site/blog/2024-04-13-imagetrace/index.md",title:"Image tracing and animation",description:"The notebook focuses on tracing and animating the contours of GIF images using WLJS Notebook.",date:"2024-04-13T00:00:00.000Z",tags:[{label:"animation",permalink:"/blog/tags/animation"}],readingTime:2.58,hasTruncateMarker:!0,authors:[{name:"Kirill Vasin",title:"Maintainer",url:"https://github.com/JerryI",imageURL:"https://avatars.githubusercontent.com/u/4111822?s=48&v=4",key:"jerryi"}],frontMatter:{authors:"jerryi",enableComments:!0,slug:"image-trace",tags:["animation"]},unlisted:!1,prevItem:{title:"Procedural spider animation",permalink:"/blog/spider"},nextItem:{title:"Image and Raster were implemented!",permalink:"/blog/imageraster"}},c={authorsImageUrls:[void 0]},l=[{value:"Frame processing",id:"frame-processing",level:2},{value:"Color separation",id:"color-separation",level:2},{value:"Animating each color channel separately",id:"animating-each-color-channel-separately",level:3}];function m(e){const n={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.M)(),...e.components},{CodeMirror:i}=n;return i||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("CodeMirror",!0),(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.p,{children:"The notebook focuses on tracing and animating the contours of GIF images using WLJS Notebook."}),"\n",(0,o.jsx)(n.p,{children:"Firstly, import as a usual file"}),"\n",(0,o.jsx)(i,{children:'imgs = (*BB[*)(* Drag and drop your gif here *)(*,*)(*"1:eJxTTMoPSmNhYGAo5gcSAUX5ZZkpqSn+BSWZ+XnFaYwgCS4g4Zyfm5uaV+KUXxEMUqxsbm6exgSSBPGCSnNSg9mAjOCSosy8dLBYSFFpKpoKkDkeqYkpEFXBILO1sCgJSczMQVYCAOFrJEU="*)(*]BB*);'}),"\n",(0,o.jsxs)(n.p,{children:["Now in ",(0,o.jsx)(n.code,{children:"imgs"})," we have a sequence of images. In our case this is a dinosaur"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{alt:"giphy",src:a(5832).c+"",width:"480",height:"480"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"the source is unknown, sorry"})}),"\n",(0,o.jsx)(n.p,{children:"To trace all contours we adapt a method from @anderstood on StackExchange"}),"\n",(0,o.jsxs)(n.p,{children:["A custom function ",(0,o.jsx)(n.code,{children:"trace[ii_]"})," is defined to process each image frame."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-mathematica",children:'trace[ii_] :=\nModule[{img, pts, z, m, n, cn, f, g}, \n  img = ii;\n  img = Binarize[img~ColorConvert~"Grayscale"~ImageResize~500~Blur~3];\n  pts = DeleteDuplicates@Cases[Normal@ListContourPlot[Reverse@ImageData[img], \n       Contours -> {0.5}], _Line, -1][[1, 1]];\n\n  z = pts[[All, 1]] + I*pts[[All, 2]];\n  m = 50;\n  n = Length@z;\n  cn = 1/n*Table[Sum[z[[k]]*Exp[-I*i*k*2 Pi/n], {k, 1, n}], {i, -m, m}];\n{f[t_], g[t_]} = {Re@#, Im@#} &@\n    Sum[cn[[i + m + 1]]*Exp[I*i*t], {i, -m, m}] // ComplexExpand;\n  Function[t, {f[t], g[t]}]\n]\n'})}),"\n",(0,o.jsx)(n.p,{children:"In a nutshell it does:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Binarizes and processes the image."}),"\n",(0,o.jsxs)(n.li,{children:["Extracts contour points using the data from ",(0,o.jsx)(n.code,{children:"ListContourPlot"})," (kinda a hack \ud83d\ude03)."]}),"\n",(0,o.jsx)(n.li,{children:"Performs Fourier analysis to create a smooth curve representation."}),"\n",(0,o.jsx)(n.li,{children:"Returns a parameterized function of the contour."}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"frame-processing",children:"Frame processing"}),"\n",(0,o.jsx)(n.p,{children:"Then we need to process each frame like that"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-mathematica",children:"frames = Map[With[{f = trace[#]}, \n  Table[f[p], {p,0,2Pi,0.01}]\n]&, imgs];\n"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"it might take a while"})}),"\n",(0,o.jsx)(n.p,{children:"The processed frames are animated with a slider as follows"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-mathematica",children:"currentFrame = frames // First;\n\nEventHandler[InputRange[1,Length[imgs], 1, 1], Function[v, \n\tcurrentFrame = frames[[v]]\n]]\n\nGraphics[Line[currentFrame // Offload]]\n"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{src:a(80328).c+"",width:"800",height:"595"})}),"\n",(0,o.jsx)(n.p,{children:"However we can go further and analyze each color plotting a separate curve for it."}),"\n",(0,o.jsx)(n.h2,{id:"color-separation",children:"Color separation"}),"\n",(0,o.jsx)(n.p,{children:"To find dominant colors use can follows this approach"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-mathematica",children:'img = imgs // First;\n\n(* Convert Image Data to a List of Colors *)\ncolors = ImageData[ImageResize[img, 200], "Byte"];\ncolorsList = Flatten[colors, 1];\n\n(* Cluster Colors Using KMeans *)\nclusters = FindClusters[colorsList, 4, Method -> "KMeans"];\n\n(* Extract and Visualize Dominant Colors *)\ndominantColors = Map[Mean, clusters];\ndominantColors = Select[dominantColors, Norm[#[[;;3]]]>10 &];\ndominantColorsRGB = RGBColor /@ (dominantColors / 255)\n'})}),"\n",(0,o.jsx)(n.p,{children:"as a result we have"}),"\n",(0,o.jsx)(i,{children:'{(*VB[*)(RGBColor[{116204/126735, 124/1207, 72346/126735, 42004/42245}])(*,*)(*"1:eJxTTMoPSmNkYGAoZgESHvk5KRCeGJAIcndyzs/JLwouTyxJzghJzS3ISSxJhchzIMmnscD0+2QWlxTZKJU89Qx/a1/0ZMq5uOM+u+yLOvoO8ca4PLIv6jo5T9Hl4nt7AA1hJUk="*)(*]VB*),(*VB[*)(RGBColor[{1339/159154, 277964/397885, 35905/477462, 2365267/2387310}])(*,*)(*"1:eJxTTMoPSmNkYGAoZgESHvk5KRCeGJAIcndyzs/JLwouTyxJzghJzS3ISSxJhchzIMmnscD0+2QWlxT5pez1+GrVaF9kfnJb/beoZ/ZFE7K2LfZ02GxftJy9VDVmy3t7AA3lJL8="*)(*]VB*),(*VB[*)(RGBColor[{19736/26295, 128738/149005, 163801/447015, 443111/447015}])(*,*)(*"1:eJxTTMoPSmNkYGAoZgESHvk5KRCeGJAIcndyzs/JLwouTyxJzghJzS3ISSxJhchzIMmnscD0+2QWlxSFXeRLmsHywr6Is/vVmkNLX9sX/V+y9fOi4uv2RYeX1veU7HhvDwAkIidz"*)(*]VB*)}'}),"\n",(0,o.jsx)(n.p,{children:"On the next step we will convolve those colors with an image"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-mathematica",children:"Clamp[val_List, max_] := Clamp[val//First, max]\nClamp[val_, max_] := If[val > 0.5, 1, 0] max \n\ncolorSeparate[img_, colors_] := Table[Map[\n  Map[\n    Function[pixel, \n      Clamp[i[[;;3]] . pixel[[;;3]] / 255.0, 1]\n    ]\n  , #]&\n, img // ImageData] // Image, {i, colors}]\n"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-mathematica",children:"ImageResize[#, 100] &/@ colorSeparate[img, dominantColors] \n"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{src:a(24156).c+"",width:"1548",height:"262"})}),"\n",(0,o.jsx)(n.h3,{id:"animating-each-color-channel-separately",children:"Animating each color channel separately"}),"\n",(0,o.jsx)(n.p,{children:"Firstly we will apply curve extracting on each channel of the frame"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-mathematica",children:"framesColored = Table[Map[With[{f = trace[#]}, \n  Table[f[p], {p,0,2Pi,0.01}]\n]&, colorSeparate[frame, dominantColors] ], {frame, imgs}];\n"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-mathematica",children:"currentFrameColored = framesColored // First;\n\nEventHandler[InputRange[1,Length[imgs], 1, 1], Function[v, currentFrameColored = framesColored[[v]]]]\n\nGraphics[\n  Table[\n    With[{i=i},\n      {dominantColorsRGB[[i]], Polygon[currentFrameColored[[i]] // Offload]}\n    ]\n  , {i, Length[dominantColorsRGB]}] // Reverse\n]\n"})}),"\n",(0,o.jsxs)(n.p,{children:["Here we use ",(0,o.jsx)(n.code,{children:"Polygon"})," instead of ",(0,o.jsx)(n.code,{children:"Line"})," to get filling for each closed curve. An algorithm did not work well for all colors and we effectively have only two instead of 3"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{src:a(74092).c+"",width:"370",height:"244"})}),"\n",(0,o.jsx)(n.p,{children:"Try it on your images!"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{target:"_blank","data-noBrokenLinkCheck":!0,href:a(28384).c+"",children:(0,o.jsx)(n.strong,{children:"Image tracing.wln"})})})]})}function d(e={}){const{wrapper:n}={...(0,r.M)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(m,{...e})}):m(e)}},28384:(e,n,a)=>{a.d(n,{c:()=>o});const o=a.p+"assets/files/Image tracing-37a50adc1aba75cae50cf42b4dfd1709.wln"},24156:(e,n,a)=>{a.d(n,{c:()=>o});const o=a.p+"assets/images/Screenshot 2024-05-19 at 13.55.02-8d0ce15f1fff8ecf7957b822b4113712.png"},80328:(e,n,a)=>{a.d(n,{c:()=>o});const o=a.p+"assets/images/dino66-ezgif.com-optimize-06cdaa67e1ac833b53fb0f3e2cdc22fd.gif"},74092:(e,n,a)=>{a.d(n,{c:()=>o});const o=a.p+"assets/images/dinooo-eb7d8a033904d76580ad138a5cba1aa1.svg"},5832:(e,n,a)=>{a.d(n,{c:()=>o});const o=a.p+"assets/images/giphy-223f79f06f1ea8201612ee0336e56bb3.gif"},4552:(e,n,a)=>{a.d(n,{I:()=>t,M:()=>s});var o=a(11504);const r={},i=o.createContext(r);function s(e){const n=o.useContext(i);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),o.createElement(i.Provider,{value:n},e.children)}}}]);