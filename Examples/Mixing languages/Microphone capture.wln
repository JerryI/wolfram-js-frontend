<|"Notebook" -> <|"ReadOnly"->True, "FocusedCell" -> CellObj[JerryI`Notebook`CellObj`$478], 
   "Objects" -> <||>, "Path" -> "/users/kirill/Library/CloudStorage/OneDrive-\
Personal/\:0414\:043e\:043a\:0443\:043c\:0435\:043d\:0442\:044b/\:041a\:043e\
\:043d\:0444\:0435\:0440\:0435\:043d\:0446\:0438\:0438/DPG2023/Microphone \
capture.wln"|>, "Cells" -> 
  {<|"Data" -> ".md\n# Audio stream\nVisualize the waveform", 
    "Display" -> "codemirror", "Hash" -> 
     "67f1f8aa-0e92-45a2-8cbd-4e9f94cac45f", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <|"Hidden" -> True|>, "State" -> "Idle", 
    "Type" -> "Input", "UID" -> Null, "Notebook" -> 
     "1344b61b-f6bf-473a-a6d8-3c99ad53b703"|>, 
   <|"Data" -> "# Audio stream\nVisualize the waveform", 
    "Display" -> "markdown", "Hash" -> 
     "ea8f2302-1422-4a24-bb72-2fd6bf5d5c6b", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <||>, "State" -> "Idle", 
    "Type" -> "Output", "UID" -> Null, "Notebook" -> 
     "1344b61b-f6bf-473a-a6d8-3c99ad53b703"|>, 
   <|"Data" -> 
     ".md\n## Javascript\nGrab the data from AudioContext and send to WL", 
    "Display" -> "codemirror", "Hash" -> 
     "ec18c103-8308-41cb-9533-504a3a8186b1", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <|"Hidden" -> True|>, "State" -> "Idle", 
    "Type" -> "Input", "UID" -> Null, "Notebook" -> 
     "1344b61b-f6bf-473a-a6d8-3c99ad53b703"|>, 
   <|"Data" -> "## Javascript\nGrab the data from AudioContext and send to \
WL", "Display" -> "markdown", "Hash" -> 
     "a2b2175a-35da-4e23-8e93-cda6c3372260", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <||>, "State" -> "Idle", 
    "Type" -> "Output", "UID" -> Null, "Notebook" -> 
     "1344b61b-f6bf-473a-a6d8-3c99ad53b703"|>, 
   <|"Data" -> ".js\n\n  // Constants\n  const audioContext = new \
AudioContext();\n  const analyser = audioContext.createAnalyser();\n  const \
scriptProcessor = audioContext.createScriptProcessor(2048, 1, 1);\n  const \
chunks = [];\n\n  // Variables\n  let stream = null;\n  let input = null;\n  \
let recorder = null;\n  let recording = null;\n  let isRecording = true;\n  \
let isPlaying = false;\n\n  // Setup analyser node\n  \
analyser.smoothingTimeConstant = 0.3;\n  analyser.fftSize = 1024;\n  \n  // \
Request access to the user's microphone.\n  const requestMicrophoneAccess = \
() => { \n    if (navigator.mediaDevices) {\n      \
navigator.mediaDevices.getUserMedia({audio: true}).then(stream => {\n        \
setAudioStream(stream);\n      }, error => {\n        alert('Something went \
wrong requesting the userMedia. <br/>Please make sure you\\'re viewing this \
demo over https.');\n      });\n    } else {\n      alert('Your browser does \
not support navigator.mediadevices. <br/>This is needed for this demo to \
work. Please try again in a differen browser.');\n    }  \n  }\n\n  // Set \
all variables which needed the audio stream\n  const setAudioStream = stream \
=> {\n    stream = stream;\n    input = \
audioContext.createMediaStreamSource(stream);\n    \n    \
input.connect(analyser);\n    analyser.connect(scriptProcessor);\n    \
scriptProcessor.connect(audioContext.destination);\n    \
scriptProcessor.onaudioprocess = processInput;\n  };\n\n\n  // Process the \
microphone input\n  const processInput = audioProcessingEvent => {\n      \
const array = new Uint8Array(analyser.frequencyBinCount);\n      \
analyser.getByteTimeDomainData(array);\n\n      server.kernel.emitt('audio', \
'{'+array.map((el) => el).join(',')+'}');\n      \
//bars.push(getAverageVolume(array));\n  }  \n  \n  // Start the \
application\n\nlet state = false;\n\ncore.MicStart = async () => {\n  if \
(state) return;\n  state = true;\n  requestMicrophoneAccess(); \n  sign.style \
= \"color: red\";\n  sign.innerText = \"Recording...\";\n}\n\ncore.MicStop = \
async () => {\n  state = false;\n  input.disconnect();\n  \
analyser.disconnect();\n  scriptProcessor.disconnect();\n  \n  sign.style = \
\"color: blue\";\n  sign.innerText = \"Stopped\";\n}\n\nthis.ondestroy = () \
=> {\n  if (!state) return;\n  input.disconnect();\n  \
analyser.disconnect();\n  scriptProcessor.disconnect();\n};\n\nconst sign = \
document.createElement('div');\nsign.style = \"color: gray\";\nsign.innerText \
= \"Idle\";\n\nreturn sign;", "Display" -> "codemirror", 
    "Hash" -> "341cc888-d0b6-460d-ac00-81527623aee8", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <||>, "State" -> "Idle", 
    "Type" -> "Input", "UID" -> Null, "Notebook" -> 
     "1344b61b-f6bf-473a-a6d8-3c99ad53b703"|>, 
   <|"Data" -> "\n  // Constants\n  const audioContext = new \
AudioContext();\n  const analyser = audioContext.createAnalyser();\n  const \
scriptProcessor = audioContext.createScriptProcessor(2048, 1, 1);\n  const \
chunks = [];\n\n  // Variables\n  let stream = null;\n  let input = null;\n  \
let recorder = null;\n  let recording = null;\n  let isRecording = true;\n  \
let isPlaying = false;\n\n  // Setup analyser node\n  \
analyser.smoothingTimeConstant = 0.3;\n  analyser.fftSize = 1024;\n  \n  // \
Request access to the user's microphone.\n  const requestMicrophoneAccess = \
() => { \n    if (navigator.mediaDevices) {\n      \
navigator.mediaDevices.getUserMedia({audio: true}).then(stream => {\n        \
setAudioStream(stream);\n      }, error => {\n        alert('Something went \
wrong requesting the userMedia. <br/>Please make sure you\\'re viewing this \
demo over https.');\n      });\n    } else {\n      alert('Your browser does \
not support navigator.mediadevices. <br/>This is needed for this demo to \
work. Please try again in a differen browser.');\n    }  \n  }\n\n  // Set \
all variables which needed the audio stream\n  const setAudioStream = stream \
=> {\n    stream = stream;\n    input = \
audioContext.createMediaStreamSource(stream);\n    \n    \
input.connect(analyser);\n    analyser.connect(scriptProcessor);\n    \
scriptProcessor.connect(audioContext.destination);\n    \
scriptProcessor.onaudioprocess = processInput;\n  };\n\n\n  // Process the \
microphone input\n  const processInput = audioProcessingEvent => {\n      \
const array = new Uint8Array(analyser.frequencyBinCount);\n      \
analyser.getByteTimeDomainData(array);\n\n      server.kernel.emitt('audio', \
'{'+array.map((el) => el).join(',')+'}');\n      \
//bars.push(getAverageVolume(array));\n  }  \n  \n  // Start the \
application\n\nlet state = false;\n\ncore.MicStart = async () => {\n  if \
(state) return;\n  state = true;\n  requestMicrophoneAccess(); \n  sign.style \
= \"color: red\";\n  sign.innerText = \"Recording...\";\n}\n\ncore.MicStop = \
async () => {\n  state = false;\n  input.disconnect();\n  \
analyser.disconnect();\n  scriptProcessor.disconnect();\n  \n  sign.style = \
\"color: blue\";\n  sign.innerText = \"Stopped\";\n}\n\nthis.ondestroy = () \
=> {\n  if (!state) return;\n  input.disconnect();\n  \
analyser.disconnect();\n  scriptProcessor.disconnect();\n};\n\nconst sign = \
document.createElement('div');\nsign.style = \"color: gray\";\nsign.innerText \
= \"Idle\";\n\nreturn sign;", "Display" -> "js", 
    "Hash" -> "5dd4a3b6-ba72-4ad6-8d16-ffe6fd8a037e", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <||>, "State" -> "Idle", 
    "Type" -> "Output", "UID" -> Null, "Notebook" -> 
     "1344b61b-f6bf-473a-a6d8-3c99ad53b703"|>, 
   <|"Data" -> ".md\n## Wolfram Language\nReceive and draw", 
    "Display" -> "codemirror", "Hash" -> 
     "175b956b-a393-4bc1-97ea-69b74b9326ef", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <|"Hidden" -> True|>, "State" -> "Idle", 
    "Type" -> "Input", "UID" -> Null, "Notebook" -> 
     "1344b61b-f6bf-473a-a6d8-3c99ad53b703"|>, 
   <|"Data" -> "## Wolfram Language\nReceive and draw", 
    "Display" -> "markdown", "Hash" -> 
     "7bfeb9fc-623f-49cf-a9df-bfdaab524a66", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <||>, "State" -> "Idle", 
    "Type" -> "Output", "UID" -> Null, "Notebook" -> 
     "1344b61b-f6bf-473a-a6d8-3c99ad53b703"|>, 
   <|"Data" -> "LeakyModule[{line = {{0.,-256.}, {512.,256.}}},\n  \
EventHandler[\"audio\", Function[data,\n    \n    line = MapIndexed[{#2[[1]], \
#1}&, data];\n  ]];\n  Graphics[\n    Line[line // Offload], \n    PlotRange \
-> {{0,512}, {127-50, 127+50}},\n    \n    \"TransitionDuration\"->30, \n    \
\"TransitionType\"->\"Linear\"\n  ]\n]\n\nWith[{win = CurrentWindow[]},\n  \
EventHandler[InputButton[\"Start\"], Function[Null, FrontSubmit[MicStart[], \
\"Window\"->win]]]\n]\nWith[{win = CurrentWindow[]},\n  \
EventHandler[InputButton[\"Stop\"], Function[Null, FrontSubmit[MicStop[], \
\"Window\"->win]]]\n]", "Display" -> "codemirror", 
    "Hash" -> "376fedef-a2ae-4649-a432-92e6cba060b3", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <||>, "State" -> "Idle", 
    "Type" -> "Input", "UID" -> Null, "Notebook" -> 
     "1344b61b-f6bf-473a-a6d8-3c99ad53b703"|>, 
   <|"Data" -> "", "Display" -> "codemirror", 
    "Hash" -> "b1a52996-5cd4-4eea-96c8-5364ee6957f1", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <||>, "State" -> "Idle", 
    "Type" -> "Input", "UID" -> Null, "Notebook" -> 
     "1344b61b-f6bf-473a-a6d8-3c99ad53b703"|>}, "serializer" -> "jsfn4"|>
