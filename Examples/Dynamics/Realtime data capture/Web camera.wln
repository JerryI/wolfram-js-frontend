<|"Notebook" -> <|"FocusedCell" -> CellObj[JerryI`Notebook`CellObj`$1615], 
   "Objects" -> <||>, "Path" -> "/users/kirill/Github/wolfram-js-frontend-dev\
/Examples/Dynamics/Realtime data capture/Web camera.wln"|>, 
 "Cells" -> {<|"Data" -> ".md\n# Capture image from web-camera\nIn this \
example we use Javascript API to connect to a web-cam and send the data to \
Wolfram Language", "Display" -> "codemirror", 
    "Hash" -> "36613ca6-dea6-42dc-a411-881540faf810", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <|"Hidden" -> True|>, "State" -> "Idle", 
    "Type" -> "Input", "UID" -> Null, "Notebook" -> 
     "8318916b-3bb5-4da4-aee7-9368ad0fb41f"|>, 
   <|"Data" -> "# Capture image from web-camera\nIn this example we use \
Javascript API to connect to a web-cam and send the data to Wolfram Language"\
, "Display" -> "markdown", "Hash" -> "d7518c4c-32e0-44f9-a436-f724c2596d91", 
    "Invisible" -> False, "MetaOnly" -> False, "Props" -> <||>, 
    "State" -> "Idle", "Type" -> "Output", "UID" -> Null, 
    "Notebook" -> "8318916b-3bb5-4da4-aee7-9368ad0fb41f"|>, 
   <|"Data" -> ".md\nA simple script to connect and preview the data \
(*generated by GPT4*)", "Display" -> "codemirror", 
    "Hash" -> "74200c31-bddb-4989-b784-a2ba654e60ca", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <|"Hidden" -> True|>, "State" -> "Idle", 
    "Type" -> "Input", "UID" -> Null, "Notebook" -> 
     "8318916b-3bb5-4da4-aee7-9368ad0fb41f"|>, 
   <|"Data" -> 
     "A simple script to connect and preview the data (*generated by GPT4*)", 
    "Display" -> "markdown", "Hash" -> 
     "e61e2428-2ef6-436e-b1b2-372db96b426d", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <||>, "State" -> "Idle", 
    "Type" -> "Output", "UID" -> Null, "Notebook" -> 
     "8318916b-3bb5-4da4-aee7-9368ad0fb41f"|>, 
   <|"Data" -> ".js\n// First, create elements for the video and \
canvas\nconst video = document.createElement('video');\nconst canvas = \
document.createElement('canvas');\nconst context = \
canvas.getContext('2d');\n\nlet stream;\n\n// Set video \
constraints\ncanvas.width = 320;\ncanvas.height = 240;\n\n// Use getUserMedia \
to access the webcam\nif(navigator.mediaDevices && \
navigator.mediaDevices.getUserMedia) {\n    \
navigator.mediaDevices.getUserMedia({ video: true })\n        \
.then(function(s) {\n            stream = s;\n            video.srcObject = \
stream;\n            video.play();\n\n        })\n        \
.catch(function(error) {\n            console.log(\"Error accessing webcam: \
\", error);\n        });\n}\n\nlet animFrame;\n\n// Draw the video frame to \
the canvas\ndocument.body.appendChild(video);\nvideo.addEventListener('play', \
function() {\n    let animFrame;\n    (function draw() {\n        \
context.drawImage(video, 0, 0, canvas.width, canvas.height);\n        \
animFrame = requestAnimationFrame(draw);\n    })();\n    \n\n});\n\n    // \
Cancel animation frame on cell destroy\n    this.ondestroy = () => {\n        \
cancelAnimationFrame(animFrame);\n              \
stream.getTracks().forEach(track => track.stop());\n                \
video.srcObject = null;\n    };\n\n//our frontend function to capture the \
frame\ncore.GrabRawImage = async (args, env) => {\n  return \
Array.from(context.getImageData(0, 0, 320, 240).data);\n}\n\n// Return the \
canvas element to be rendered\nreturn canvas;", "Display" -> "codemirror", 
    "Hash" -> "0e5d8034-b61c-4773-afe9-a9dea16fe7e0", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <||>, "State" -> "Idle", 
    "Type" -> "Input", "UID" -> Null, "Notebook" -> 
     "8318916b-3bb5-4da4-aee7-9368ad0fb41f"|>, 
   <|"Data" -> "// First, create elements for the video and canvas\nconst \
video = document.createElement('video');\nconst canvas = \
document.createElement('canvas');\nconst context = \
canvas.getContext('2d');\n\nlet stream;\n\n// Set video \
constraints\ncanvas.width = 320;\ncanvas.height = 240;\n\n// Use getUserMedia \
to access the webcam\nif(navigator.mediaDevices && \
navigator.mediaDevices.getUserMedia) {\n    \
navigator.mediaDevices.getUserMedia({ video: true })\n        \
.then(function(s) {\n            stream = s;\n            video.srcObject = \
stream;\n            video.play();\n\n        })\n        \
.catch(function(error) {\n            console.log(\"Error accessing webcam: \
\", error);\n        });\n}\n\nlet animFrame;\n\n// Draw the video frame to \
the canvas\ndocument.body.appendChild(video);\nvideo.addEventListener('play', \
function() {\n    let animFrame;\n    (function draw() {\n        \
context.drawImage(video, 0, 0, canvas.width, canvas.height);\n        \
animFrame = requestAnimationFrame(draw);\n    })();\n    \n\n});\n\n    // \
Cancel animation frame on cell destroy\n    this.ondestroy = () => {\n        \
cancelAnimationFrame(animFrame);\n              \
stream.getTracks().forEach(track => track.stop());\n                \
video.srcObject = null;\n    };\n\ncore.GrabRawImage = async (args, env) => \
{\n  return Array.from(context.getImageData(0, 0, 320, 240).data);\n}\n\n// \
Return the canvas element to be rendered\nreturn canvas;", "Display" -> "js", 
    "Hash" -> "cde7a7eb-66a4-4732-aceb-7ddd2e7f1aa7", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <||>, "State" -> "Idle", 
    "Type" -> "Output", "UID" -> Null, "Notebook" -> 
     "8318916b-3bb5-4da4-aee7-9368ad0fb41f"|>, 
   <|"Data" -> ".md\nThe image data is in format RGBA and 8-bits for each \
channel. Let us fetch it", "Display" -> "codemirror", 
    "Hash" -> "1c6b76a1-4cbb-4ea6-9c48-9346bb674447", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <|"Hidden" -> True|>, "State" -> "Idle", 
    "Type" -> "Input", "UID" -> Null, "Notebook" -> 
     "8318916b-3bb5-4da4-aee7-9368ad0fb41f"|>, 
   <|"Data" -> "The image data is in format RGBA and 8-bits for each channel. \
Let us fetch it", "Display" -> "markdown", 
    "Hash" -> "42ee8a59-902b-4bfd-bb37-22cbdba46874", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <||>, "State" -> "Idle", 
    "Type" -> "Output", "UID" -> Null, "Notebook" -> 
     "8318916b-3bb5-4da4-aee7-9368ad0fb41f"|>, 
   <|"Data" -> "test = With[{raw = FrontFetch[GrabRawImage[]]},\n  \
Partition[Partition[raw, 4], 320] // NumericArray // Image \n]", 
    "Display" -> "codemirror", "Hash" -> 
     "168cee76-6dcd-4413-aa1e-1121eaf7ef6a", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <||>, "State" -> "Idle", 
    "Type" -> "Input", "UID" -> Null, "Notebook" -> 
     "8318916b-3bb5-4da4-aee7-9368ad0fb41f"|>, 
   <|"Data" -> ".md\nlet s impaint for instance ;)", 
    "Display" -> "codemirror", "Hash" -> 
     "9ce6b5b6-f7bb-495c-9f17-11e64a1845d2", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <|"Hidden" -> True|>, "State" -> "Idle", 
    "Type" -> "Input", "UID" -> Null, "Notebook" -> 
     "8318916b-3bb5-4da4-aee7-9368ad0fb41f"|>, 
   <|"Data" -> "let s impaint for instance ;)", "Display" -> "markdown", 
    "Hash" -> "d487ea66-fd43-4495-8b17-3d67f87598ab", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <||>, "State" -> "Idle", 
    "Type" -> "Output", "UID" -> Null, "Notebook" -> 
     "8318916b-3bb5-4da4-aee7-9368ad0fb41f"|>, 
   <|"Data" -> "canvas = ImagePad[test, 100, White];\nmask = Binarize[canvas, \
{1, 1}];\n\nInpaint[canvas, mask, \n  Method -> {\"TextureSynthesis\", \
\"NeighborCount\" -> 20, \n    \"MaxSamples\" -> 1000}]", 
    "Display" -> "codemirror", "Hash" -> 
     "e8bcdb6e-2221-4f98-b4d9-572354de2b9f", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <||>, "State" -> "Idle", 
    "Type" -> "Input", "UID" -> Null, "Notebook" -> 
     "8318916b-3bb5-4da4-aee7-9368ad0fb41f"|>}, "serializer" -> "jsfn4"|>
