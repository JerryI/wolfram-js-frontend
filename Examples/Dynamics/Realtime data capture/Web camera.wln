<|"Notebook" -> <|"ReadOnly"->True, "FocusedCell" -> CellObj[JerryI`Notebook`CellObj`$381], 
   "Objects" -> <||>, "Path" -> "/users/kirill/Github/wolfram-js-frontend-dev\
/Examples/Dynamics/Realtime data capture/Web camera.wln"|>, 
 "Cells" -> {<|"Data" -> ".md\n# Capture image from web-camera\nIn this \
example we use Javascript API to connect to a web-cam and send the data to \
Wolfram Language", "Display" -> "codemirror", 
    "Hash" -> "00944e76-e135-4580-b544-385ec4b52452", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <|"Hidden" -> True|>, "State" -> "Idle", 
    "Type" -> "Input", "UID" -> Null, "Notebook" -> 
     "c3a1d10e-fd60-462f-8d5d-4178288e9c29"|>, 
   <|"Data" -> "# Capture image from web-camera\nIn this example we use \
Javascript API to connect to a web-cam and send the data to Wolfram Language"\
, "Display" -> "markdown", "Hash" -> "87bd3bfd-c84f-4956-9d85-80400d9028b3", 
    "Invisible" -> False, "MetaOnly" -> False, "Props" -> <||>, 
    "State" -> "Idle", "Type" -> "Output", "UID" -> Null, 
    "Notebook" -> "c3a1d10e-fd60-462f-8d5d-4178288e9c29"|>, 
   <|"Data" -> ".md\nA simple script to connect and preview the data \
(*generated by GPT4*)", "Display" -> "codemirror", 
    "Hash" -> "27c3d8d5-09e4-4463-a7b1-79593875373e", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <|"Hidden" -> True|>, "State" -> "Idle", 
    "Type" -> "Input", "UID" -> Null, "Notebook" -> 
     "c3a1d10e-fd60-462f-8d5d-4178288e9c29"|>, 
   <|"Data" -> 
     "A simple script to connect and preview the data (*generated by GPT4*)", 
    "Display" -> "markdown", "Hash" -> 
     "a815504e-b2eb-4960-90ad-63ad27f51554", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <||>, "State" -> "Idle", 
    "Type" -> "Output", "UID" -> Null, "Notebook" -> 
     "c3a1d10e-fd60-462f-8d5d-4178288e9c29"|>, 
   <|"Data" -> ".js\n// First, create elements for the video and \
canvas\nconst video = document.createElement('video');\nconst canvas = \
document.createElement('canvas');\nconst context = \
canvas.getContext('2d');\n\nlet stream;\n\n// Set video \
constraints\ncanvas.width = 320;\ncanvas.height = 240;\n\n// Use getUserMedia \
to access the webcam\nif(navigator.mediaDevices && \
navigator.mediaDevices.getUserMedia) {\n    \
navigator.mediaDevices.getUserMedia({ video: true })\n        \
.then(function(s) {\n            stream = s;\n            video.srcObject = \
stream;\n            video.play();\n\n        })\n        \
.catch(function(error) {\n            console.log(\"Error accessing webcam: \
\", error);\n        });\n}\n\nlet animFrame;\n\n// Draw the video frame to \
the canvas\ndocument.body.appendChild(video);\nvideo.addEventListener('play', \
function() {\n    let animFrame;\n    (function draw() {\n        \
context.drawImage(video, 0, 0, canvas.width, canvas.height);\n        \
animFrame = requestAnimationFrame(draw);\n    })();\n    \n\n});\n\n    // \
Cancel animation frame on cell destroy\n    this.ondestroy = () => {\n        \
cancelAnimationFrame(animFrame);\n              \
stream.getTracks().forEach(track => track.stop());\n                \
video.srcObject = null;\n    };\n\n//our frontend function to capture the \
frame\ncore.GrabRawImage = async (args, env) => {\n  return \
Array.from(context.getImageData(0, 0, 320, 240).data);\n}\n\n// Return the \
canvas element to be rendered\nreturn canvas;", "Display" -> "codemirror", 
    "Hash" -> "6fb66798-c6be-49b9-9fe8-ab48842bda33", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <|"Fade" -> True|>, "State" -> "Idle", 
    "Type" -> "Input", "UID" -> Null, "Notebook" -> 
     "c3a1d10e-fd60-462f-8d5d-4178288e9c29"|>, 
   <|"Data" -> "// First, create elements for the video and canvas\nconst \
video = document.createElement('video');\nconst canvas = \
document.createElement('canvas');\nconst context = \
canvas.getContext('2d');\n\nlet stream;\n\n// Set video \
constraints\ncanvas.width = 320;\ncanvas.height = 240;\n\n// Use getUserMedia \
to access the webcam\nif(navigator.mediaDevices && \
navigator.mediaDevices.getUserMedia) {\n    \
navigator.mediaDevices.getUserMedia({ video: true })\n        \
.then(function(s) {\n            stream = s;\n            video.srcObject = \
stream;\n            video.play();\n\n        })\n        \
.catch(function(error) {\n            console.log(\"Error accessing webcam: \
\", error);\n        });\n}\n\nlet animFrame;\n\n// Draw the video frame to \
the canvas\ndocument.body.appendChild(video);\nvideo.addEventListener('play', \
function() {\n    let animFrame;\n    (function draw() {\n        \
context.drawImage(video, 0, 0, canvas.width, canvas.height);\n        \
animFrame = requestAnimationFrame(draw);\n    })();\n    \n\n});\n\n    // \
Cancel animation frame on cell destroy\n    this.ondestroy = () => {\n        \
cancelAnimationFrame(animFrame);\n              \
stream.getTracks().forEach(track => track.stop());\n                \
video.srcObject = null;\n    };\n\ncore.GrabRawImage = async (args, env) => \
{\n  return Array.from(context.getImageData(0, 0, 320, 240).data);\n}\n\n// \
Return the canvas element to be rendered\nreturn canvas;", "Display" -> "js", 
    "Hash" -> "423e48c9-ab8b-4244-af0f-84f01d5a00bf", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <||>, "State" -> "Idle", 
    "Type" -> "Output", "UID" -> Null, "Notebook" -> 
     "c3a1d10e-fd60-462f-8d5d-4178288e9c29"|>, 
   <|"Data" -> ".md\nThe image data is in format RGBA and 8-bits for each \
channel. Let us fetch it", "Display" -> "codemirror", 
    "Hash" -> "172392ca-42db-448c-bcc4-9863c0cac53a", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <|"Hidden" -> True|>, "State" -> "Idle", 
    "Type" -> "Input", "UID" -> Null, "Notebook" -> 
     "c3a1d10e-fd60-462f-8d5d-4178288e9c29"|>, 
   <|"Data" -> "The image data is in format RGBA and 8-bits for each channel. \
Let us fetch it", "Display" -> "markdown", 
    "Hash" -> "41b7e3eb-8a88-4761-a978-ee18f0a2a056", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <||>, "State" -> "Idle", 
    "Type" -> "Output", "UID" -> Null, "Notebook" -> 
     "c3a1d10e-fd60-462f-8d5d-4178288e9c29"|>, 
   <|"Data" -> "test = With[{raw = FrontFetch[GrabRawImage[]]},\n  \
Partition[Partition[raw, 4], 320] // NumericArray // Image \n]", 
    "Display" -> "codemirror", "Hash" -> 
     "aa0c46d6-f318-4cf2-9e85-0ce83c041cd7", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <||>, "State" -> "Idle", 
    "Type" -> "Input", "UID" -> Null, "Notebook" -> 
     "c3a1d10e-fd60-462f-8d5d-4178288e9c29"|>, 
   <|"Data" -> ".md\nlet s impaint for instance ;)", 
    "Display" -> "codemirror", "Hash" -> 
     "a770483d-c135-40f9-a5a2-047a66acc59e", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <|"Hidden" -> True|>, "State" -> "Idle", 
    "Type" -> "Input", "UID" -> Null, "Notebook" -> 
     "c3a1d10e-fd60-462f-8d5d-4178288e9c29"|>, 
   <|"Data" -> "let s impaint for instance ;)", "Display" -> "markdown", 
    "Hash" -> "d787044a-8a27-4f56-ab04-9007b414f9f3", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <||>, "State" -> "Idle", 
    "Type" -> "Output", "UID" -> Null, "Notebook" -> 
     "c3a1d10e-fd60-462f-8d5d-4178288e9c29"|>, 
   <|"Data" -> "canvas = ImagePad[test, 100, White];\nmask = Binarize[canvas, \
{1, 1}];\n\nInpaint[canvas, mask, \n  Method -> {\"TextureSynthesis\", \
\"NeighborCount\" -> 20, \n    \"MaxSamples\" -> 1000}]", 
    "Display" -> "codemirror", "Hash" -> 
     "2cbf9e51-42c4-4bdb-ba0d-dd414e229e12", "Invisible" -> False, 
    "MetaOnly" -> False, "Props" -> <||>, "State" -> "Idle", 
    "Type" -> "Input", "UID" -> Null, "Notebook" -> 
     "c3a1d10e-fd60-462f-8d5d-4178288e9c29"|>}, "serializer" -> "jsfn4"|>
